# pipeline-sas
SimulaciÃ³n de pipeline bancario con SAS + Python + AWS.

# Data Pipeline â€“ SAS + Python + AWS (SimulaciÃ³n)

Este proyecto simula un **pipeline bancario de datos** como los que se desarrollan en empresas de consultorÃ­a tecnolÃ³gica para el sector financiero.  
Incluye **ingesta de datos, limpieza, transformaciÃ³n, KPIs y visualizaciÃ³n**, usando **SAS, Python y AWS**.

---

## ğŸ¯ Objetivos del proyecto
- Construir un **pipeline de datos de clientes y transacciones** bancarias.  
- Practicar el uso de **SAS Base, Enterprise Guide y PROC SQL**.  
- Integrar Python como orquestador/ETL (simulaciÃ³n de AWS S3).  
- Generar **reportes y dashboards** para stakeholders de negocio.  
- Demostrar **buenas prÃ¡cticas de versionado y documentaciÃ³n con Git**.  

---

## ğŸ“‚ Estructura del repositorio

pipeline-sas/
â”‚
â”œâ”€â”€ data/ # Datos de prueba (clientes.csv, transacciones.csv)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ sas/ # CÃ³digo SAS (ingesta, limpieza, KPIs, reportes)
â”‚ â”œâ”€â”€ python/ # Scripts Python (ETL, integraciÃ³n S3)
â”‚
â”œâ”€â”€ notebooks/ # Notebooks de exploraciÃ³n (EDA, PySpark demo)
â”œâ”€â”€ reports/ # Salidas: tablas SAS, capturas dashboards
â”œâ”€â”€ tests/ # Validaciones de calidad de datos
â”‚
â”œâ”€â”€ README.md # DocumentaciÃ³n principal
â”œâ”€â”€ requirements.txt # Dependencias Python

---

## âš™ï¸ TecnologÃ­as utilizadas

### Lenguajes
- **SAS Base / PROC SQL / DATA step**
- **Python 3 (pandas, boto3, pytest)**
- **SQL (consultas y joins)**
- **(Opcional) Scala/Java** para batch jobs

### Cloud & OrquestaciÃ³n
- **AWS S3** (simulado/local para ingesta)
- **Airflow** (para DAGs de pipelines)
- **Docker** (para empaquetar procesos)

### VisualizaciÃ³n
- **Power BI**
- **Looker Studio**

---

## ğŸ”§ Pipeline de datos â€“ Fases

### 1. Ingesta
- Archivos CSV (`clientes.csv`, `transacciones.csv`).  
- En proyecto real, llegarÃ­an desde **SFTP, API REST o bucket S3**.  

Ejemplo SAS:

%LET path = /home/uXXXXX;  /* Macrovariable ruta */

DATA clientes;
    INFILE "&path./clientes.csv" DSD FIRSTOBS=2;
    INPUT id_cliente nombre :$30. ciudad :$20. segmento :$15. fecha_registro :yymmdd10.;
    FORMAT fecha_registro yymmdd10.;
RUN;

Ejemplo python

import boto3
s3 = boto3.client("s3")
s3.download_file("bucket", "transacciones/2025-09-01.csv", "data/transacciones.csv")

2. Limpieza

ValidaciÃ³n de montos (monto > 0).

NormalizaciÃ³n de texto (tipo, canal).

Filtrado de datos invÃ¡lidos.

Ejemplo SAS:

DATA transacciones_clean;
    SET transacciones;
    IF monto <= 0 THEN DELETE;
    tipo = PROPCASE(tipo);
    canal = PROPCASE(canal);
RUN;

3. TransformaciÃ³n

KPI por cliente: total transacciones.

KPI por ciudad: sumatoria de montos.

Ejemplo PROC SQL:

PROC SQL;
    CREATE TABLE kpi_ciudad AS
    SELECT ciudad, SUM(monto) AS total_ciudad
    FROM transacciones_clean t
    INNER JOIN clientes c ON t.id_cliente = c.id_cliente
    GROUP BY ciudad;
QUIT;

4. Reportes

PROC REPORT â†’ tablas agregadas.

ExportaciÃ³n a CSV/Excel.

Dashboard en Power BI (simulaciÃ³n).

5. Tests de calidad

Ejemplo en Python con pytest:

import pandas as pd

def test_montos_positivos():
    df = pd.read_csv("data/transacciones.csv")
    assert (df["monto"] > 0).all(), "Existen transacciones con monto no vÃ¡lido"

ğŸ“Š Resultados esperados

Tablas SAS con KPIs (kpi_cliente, kpi_ciudad).

Dashboard con grÃ¡ficos de:

Total transacciones por ciudad.

DistribuciÃ³n por canal.

Top clientes por monto.

Validaciones automÃ¡ticas en tests.

ğŸ“… Roadmap

 Generar datasets de prueba (clientes + transacciones).

 Cargar y limpiar en SAS.

 KPIs en PROC SQL.

 Integrar Python con S3 simulado.

 Dashboard en Power BI.

 Pipeline completo en Airflow.

ğŸ‘¤ Autor

Felipe Duque
Ingeniero en Sistemas y Telecomunicaciones | Analista & Data Engineer.
